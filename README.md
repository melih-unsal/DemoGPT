# ü§ñ From Demo to Product: The All-in-One Agent Library

<p align="center">
<a href=""><img src="assets/banner_small.png" alt="DemoGPT logo: Generate automatic LangChain pipelines" width="450px"></a>
</p>

<p align="center">
<b>‚ö° Everything you need to create an LLM Agent is here. Access a comprehensive suite of tools, prompts, frameworks, and a knowledge hub of LLM models‚Äîall in one place to streamline your agent development.</b>
</p>

<p align="center">
<a href="https://pepy.tech/project/demogpt"><img src="https://static.pepy.tech/badge/demogpt" alt="Downloads"></a>
<a href="https://github.com/melih-unsal/DemoGPT/releases"><img src="https://img.shields.io/github/release/melih-unsal/DemoGPT" alt="Releases"></a>
<a href="https://demogpt.io"><img src="https://img.shields.io/badge/Official%20Website-demogpt.io-blue?style=flat&logo=world&logoColor=white" alt="Official Website"></a>
<a href="https://docs.demogpt.io"><img src="https://img.shields.io/badge/Documentation-üìò-blueviolet" alt="DemoGPT Documentation"></a>
</p>

<p align="center">
<a href="docs/README_CN.md"><img src="https://img.shields.io/badge/ÊñáÊ°£-‰∏≠ÊñáÁâà-blue.svg" alt="CN doc"></a>
<a href="README.md"><img src="https://img.shields.io/badge/document-English-blue.svg" alt="EN doc"></a>
<a href="docs/ROADMAP_CN.md"><img src="https://img.shields.io/badge/ROADMAP-Ë∑ØÁ∫øÂõæ-blue" alt="roadmap"></a>
<a href="docs/ROADMAP.md"><img src="https://img.shields.io/badge/ROADMAP-english-red" alt="roadmap"></a>
<a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT"></a>
</p>

<p align="center">
<a href="https://github.com/melih-unsal/DemoGPT/issues?q=is%3Aopen+is%3Aissue"><img src="https://img.shields.io/github/issues/melih-unsal/DemoGPT.svg?maxAge=2592000000000000" alt="Open an issue"></a>
<a href="https://github.com/melih-unsal/DemoGPT/issues?q=is%3Aissue+is%3Aclosed"><img src="https://img.shields.io/github/issues-closed-raw/melih-unsal/DemoGPT.svg?maxAge=25920000000000000000" alt="Closed issues"></a>
<a href="https://star-history.com/#melih-unsal/DemoGPT"><img src="https://img.shields.io/github/stars/melih-unsal/DemoGPT?style=social" alt="DemoGPT  Stars"></a>
<a href=""><img src="https://img.shields.io/github/forks/melih-unsal/DemoGPT" /> </a>
</p>

<p align="center">
<a href="https://twitter.com/demo_gpt"><img src="https://img.shields.io/twitter/follow/demo_gpt?style=social" alt="Twitter Follow"></a>
<a href="https://demogpt.medium.com/"><img src="https://img.shields.io/static/v1?style=for-the-badge&message=Medium&color=000000&logo=Medium&logoColor=FFFFFF&label=" alt="DemoGPT Medium" height="20"/></a>
<a href="https://www.producthunt.com/posts/demogpt?utm_source=badge-featured&utm_medium=badge&utm_souce=badge-demogpt" target="_blank"><img src="https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=406106&theme=light" alt="DemoGPT - Auto&#0032;generative&#0032;AI&#0032;app&#0032;generator&#0032;with&#0032;the&#0032;power&#0032;of&#0032;Llama&#0032;2 | Product Hunt" height="20" /></a>
</p>

<p align="center">
<a href="https://demogpt.streamlit.app"><img src="https://static.streamlit.io/badges/streamlit_badge_black_white.svg" alt="Streamlit application"></a>
<a href="https://huggingface.co/spaces/melihunsal/demogpt"><img src="https://img.shields.io/badge/%F0%9F%A4%97-Spaces-yellow"></a>
</p>

## üìë Table of Contents

- [Introduction](#-introduction)
- [Architecture](#Ô∏è-architecture)
- [Installation](#-installation)
- [Usage](#-usage)
  - [Package Version](#-for-the-package-version)
  - [Python Interface](#-for-the-python-interface)
  - [Source Code Version](#-for-the-source-code-version)
- [DemoGPT AgentHub](#-demogpt-agenthub)
  - [Installation](#-installation-1)
  - [Creating Tools](#-creating-tools)
  - [Available Tools](#-available-tools)
  - [Creating an Agent](#-creating-an-agent)
  - [Using an Agent](#-using-an-agent)
  - [Available Agent Types](#-available-agent-types)
  - [Using ReactAgent](#-using-reactagent)
  - [Using RAG](#-using-rag)
  - [Combining RAG with Agents](#-combining-rag-with-agents)
- [To-Do](#to-do-)
- [Contribute](#-contribute)
- [Citations](#-citations)
- [License](#-license)

## ü§ñ DemoGPT AgentHub

DemoGPT AgentHub is a powerful library that allows you to create, customize, and use AI agents with various tools.

### üõ† Installation

To use DemoGPT AgentHub, simply install the main package:

```bash 
pip install demogpt
```

### üîß Creating Tools

Creating custom tools is easy:

```python
from demogpt_agenthub.tools import BaseTool
class MyCustomTool(BaseTool):
    def __init__(self):
        self.name = "MyCustomTool"
        self.description = "This tool does something amazing!"
        super().__init__()
    def run(self, query):
        # Implement your tool's functionality here
        return f"Result for: {query}"
```

**Example Usage:**
```python
my_tool = MyCustomTool()
agent = ToolCallingAgent(tools=[my_tool], llm=llm, verbose=True)
agent.run("Can you use my custom tool?")
```

**Example Output:**
```
Reasoning:
The user is asking to use the custom tool called MyCustomTool. This tool is described as doing "something amazing", so I will use it to process the query.
Tool call:
MyCustomTool
Tool result:
Result for: Can you use my custom tool?
Answer:
Yes, I successfully used your custom tool! The tool processed your query and returned the following result: "Result for: Can you use my custom tool?"
```

### üß∞ Available Tools

DemoGPT AgentHub comes with several built-in tools:

- üîç DuckDuckGoSearchTool
- üå¶ WeatherTool
- üìö WikipediaTool
- üêö BashTool
- üêç PythonTool
- üìÑ ArxivTool
- üé• YouTubeSearchTool
- üíª StackOverFlowTool
- üåê RequestUrlTool
- üóÉ WikiDataTool
- üè• PubmedTool

### ü§ñ Creating an Agent

To create an agent:

```python
from demogpt_agenthub.agents import ToolCallingAgent
from demogpt_agenthub.llms import OpenAIChatModel
from demogpt_agenthub.tools import DuckDuckGoSearchTool, WeatherTool

search_tool = DuckDuckGoSearchTool()
weather_tool = WeatherTool()
llm = OpenAIChatModel(model_name="gpt-4o-mini")
agent = ToolCallingAgent(tools=[search_tool, weather_tool], llm=llm, verbose=True)
```

### üéÆ Using an Agent

Once you've created an agent, use it to ask questions or perform tasks:

```python
query = "What's the weather like in New York today?"
response = agent.run(query)
print(response)
```

**Example Output:**

```
Removing existing vectorstore at rag_chroma
Decision:
False
Reasoning:
To find the weather in New York today, I first need to retrieve the current weather information. After obtaining the weather information, I can provide you with the current weather conditions. The RAG tool will help me find out the current weather in New York.
Tool call:
RAG
Tool args:
{'query': 'weather in New York today'}
Tool result:
In New York, the current weather is as follows:
Detailed status: clear sky
Wind speed: 2.57 m/s, direction: 240¬∞
Humidity: 56%
Temperature: 
  - Current: 24.36¬∞C
  - High: 25.74¬∞C
  - Low: 22.05¬∞C
  - Feels like: 24.46¬∞C
Rain: {}
Heat index: None
Cloud cover: 0%
Answer:
The current weather in New York is clear sky with a temperature of 24.36¬∞C (feels like 24.46¬∞C). The humidity is at 56% with a wind speed of 2.57 m/s from the direction of 240¬∞. There is 0% cloud cover.
```

This example demonstrates how an agent can:
1. Access document information through RAG
2. Use Python for calculations
3. Combine multiple tools to answer complex questions

The agent will:
1. Use RAG to find information about the current weather in New York
2. Use the Python tool to calculate the current weather conditions
3. Provide a comprehensive answer using both pieces of information

### üß∞ Example: Creating a Simple Math Tool

Here's an example of creating a custom power calculation tool:

```python
from demogpt_agenthub.tools import BaseTool
class MyPowerTool(BaseTool):
    def __init__(self):
        self.name = "MyPowerTool"
        self.description = "This tool is used to calculate the power of a number"
        super().__init__()
    def run(self, a: int, b: int):
        # Implement your tool's functionality here
        return a**b

power_tool = MyPowerTool()
agent = ToolCallingAgent(tools=[search_tool, weather_tool, power_tool], llm=llm, verbose=True)
agent.run("What is the 34 to the power of 26?")
```

**Example Output:**
```
Reasoning:
The task is to calculate a number raised to the power of another. The most appropriate tool for this calculation is MyPowerTool, which is specifically designed for power calculations.
Tool call:
MyPowerTool
Tool result:
6583424253569334549714045134721532297216
Answer:
34 to the power of 26 is 6583424253569334549714045134721532297216.
```

### üß† Using ReactAgent

The ReactAgent provides a detailed reasoning process:

```python
from demogpt_agenthub.tools import DuckDuckGoSearchTool, WeatherTool, PythonTool
from demogpt_agenthub.llms import OpenAIChatModel
from demogpt_agenthub.agents import ReactAgent

search_tool = DuckDuckGoSearchTool()
weather_tool = WeatherTool()
python_tool = PythonTool()

agent = ReactAgent(
    tools=[search_tool, weather_tool, python_tool],
    llm=OpenAIChatModel(model_name="gpt-4o-mini"),
    verbose=True
)

query = "What is the weather's temperature's square root in the country where Cristiano Ronaldo is currently playing?"
print(agent.run(query))
```

**Example Output:**
```
Decision:
False
Reasoning:
First, I need to determine the current location where Christiano Ronaldo is playing in order to fetch the current temperature. Then I will use the OpenWeatherMap tool to get the temperature information. Finally, I will calculate the square root of the temperature using the Python Interpreter tool for precise computation.
Tool call:
duckduckgo_search
Tool args:
{'inp': 'Where is Christiano Ronaldo currently playing?'}
Tool result:
Ronaldo started Al Nassr's home match against Saudi Pro League leaders Al Ittihad on May 7. Stefano Pioli's men went into a 2-0 first-half lead but were beaten 3-2 when Houssem Aouar stuck in ... Cristiano Ronaldo and his Al Nassr team endured disappointment in 2023/24 as they failed to win the Saudi Pro League or the AFC Champions League. After Sadio Mane, Seko Fofana, Marcelo Brozovic ... Yes, Cristiano Ronaldo will be in the lineup to play tonight. Now that they once again failed to win the AFC Champions League Elite, Ronaldo will still have some optimism that they can win the league despite being eight points behind Al Ittihad. Despite the club's poor season, Ronaldo has maintained his goalscoring form, netting 23 goals in ... Cristiano Ronaldo currently plays for Al Nassr in the Saudi Pro League. The Portugal international transferred from Manchester United in December 2022 and inked a two-and-a-half-year contract with ... Is Cristiano Ronaldo playing Today? Cristiano Ronaldo is expected to start in today's crucial match. The Portuguese star remains Al Nassr's top scorer in the AFC Champions League, with six goals to his name. His outstanding form has played a pivotal role in the team's journey to the semifinals‚Äînow just one win away from reaching a continental final for the first time since 1995, when ...
Decision:
False
Reasoning:
I need to fetch the current temperature in Saudi Arabia where Cristiano Ronaldo is playing, using the OpenWeatherMap tool. After obtaining the temperature, I will compute its square root using the Python Interpreter tool.
Tool call:
open_weather_map
Tool args:
{'city': 'Riyadh,SA'}
Tool result:
In Riyadh,SA, the current weather is as follows:
Detailed status: clear sky
Wind speed: 5.44 m/s, direction: 150¬∞
Humidity: 7%
Temperature: 
  - Current: 39.16¬∞C
  - High: 39.16¬∞C
  - Low: 39.16¬∞C
  - Feels like: 35.82¬∞C
Rain: {}
Heat index: None
Cloud cover: 0%
Decision:
False
Reasoning:
I need to calculate the square root of the current temperature in Saudi Arabia, which is 39.16¬∞C. I will use the Python Interpreter tool for precise calculation.
Tool call:
Python Interpreter
Tool args:
{'code': 'import math\nresult = math.sqrt(39.16)\nprint(result)'}
Tool result:
6.257795138864806

Decision:
True
Answer:
The square root of the current temperature in Saudi Arabia, where Cristiano Ronaldo is playing, is approximately 6.26.
```

### üßÆ Using RAG

BaseRAG provides an easy way to implement Retrieval Augmented Generation with various vector stores:

```python
from demogpt_agenthub.rag import BaseRAG
from demogpt_agenthub.llms import OpenAIChatModel

# Initialize RAG system
rag = BaseRAG(
    llm=OpenAIChatModel(model_name="gpt-4o-mini"), 
    vectorstore="chroma",  # Supports "chroma", "pinecone", "faiss"
    persistent_path="rag_chroma",  # Where to store the vector database
    index_name="rag_index",
    reset_vectorstore=True,  # Whether to reset existing vectorstore
    embedding_model_name="sentence-transformers/all-mpnet-base-v2",  # Or use OpenAI models
    filter={"search_kwargs": {"score_threshold": 0.5}}
)

# Add documents
rag.add_files(["~/Downloads/Resume.pdf"])  # Supports PDF, TXT, CSV, JSON

# Query the RAG system
response = rag.run("What is the GitHub repo of the person?")
print(response)
```

**Example Output:**
```
Removing existing vectorstore at rag_chroma
The GitHub repository of the person is called DemoGPT, and it can be found at https://github.com/melih-unsal.
```

**Another Query Example:**
```python
rag.run("How many stars does the GitHub repo have?")
```

**Output:**
```
The GitHub repo has 1.8K stars.
```

These examples provide users with a clear understanding of:
1. What to expect when running these code blocks
2. The format of the output
3. How different agents and tools behave
4. How the reasoning process works in the ReactAgent
5. How RAG responds to questions

### üîÑ Combining RAG with Agents

You can also use RAG within agents to enable document-based reasoning. Here's an example:

```python
from demogpt_agenthub.tools import PythonTool
from demogpt_agenthub.llms import OpenAIChatModel
from demogpt_agenthub.agents import ReactAgent
from demogpt_agenthub.rag import BaseRAG

# Initialize RAG system
rag = BaseRAG(
    llm=OpenAIChatModel(model_name="gpt-4o-mini"), 
    vectorstore="chroma", 
    persistent_path="rag_chroma", 
    index_name="rag_index",
    reset_vectorstore=True,
    embedding_model_name="sentence-transformers/all-mpnet-base-v2",
    filter={"search_kwargs": {"score_threshold": 0.5}}
)

# Add your documents
rag.add_files(["~/Downloads/Melih_√úNSAL_Resume.pdf"])

# Create an agent with RAG and other tools
python_tool = PythonTool()
agent = ReactAgent(
    tools=[python_tool, rag], 
    llm=OpenAIChatModel(model_name="gpt-4o-mini"), 
    verbose=True
)

# Use the agent with both RAG and other tools
query = "What is the square root of the number of stars of the github repo of Melih?"
print(agent.run(query))
```

**Example Output:**
```
Removing existing vectorstore at rag_chroma
Decision:
False
Reasoning:
To find the square root of the number of stars in Melih's GitHub repo, I first need to retrieve the current number of stars for that repository. After obtaining that number, I can compute its square root. The RAG tool will help me find out the number of stars, and then I'll use the Python Interpreter to calculate the square root.
Tool call:
RAG
Tool args:
{'query': 'number of stars in the GitHub repository of Melih'}
Tool result:
The GitHub repository of Melih √úNSAL has 1.8K stars.
Decision:
False
Reasoning:
I need to calculate the square root of 1.8K stars, which is equivalent to 1800 stars. To perform this calculation, I will use the Python Interpreter tool to compute the square root.
Tool call:
Python Interpreter
Tool args:
{'code': 'import math\nresult = math.sqrt(1800)\nprint(result)'}
Tool result:
42.42640687119285

Decision:
True
Answer:
The square root of the number of stars in Melih's GitHub repository, which is 1.8K (or 1800 stars), is approximately 42.43.
```

This example demonstrates how an agent can:
1. Access document information through RAG
2. Use Python for calculations
3. Combine multiple tools to answer complex questions

The agent will:
1. Use RAG to find information about the GitHub repository stars
2. Use the Python tool to calculate the square root
3. Provide a comprehensive answer using both pieces of information

## üî• Demo


![Tweet Generator](assets/web_blogger.gif)

## üìö Documentation

See our documentation site [here](https://docs.demogpt.io/) for full how-to docs and guidelines

‚ö° With DemoGPT v1.3, API usage will be possible with the power of **Gorilla** within 2 weeks.
After this release, you will be able use external APIs autonomously. ‚ö°

## üì¶ Using DemoGPT Package

The DemoGPT package is now available and can be installed using pip. Run the following command to install the package:

```sh
pip install demogpt
```

To use the DemoGPT application, simply type "demogpt" into your terminal:

```sh
demogpt
```


## üìå Introduction

Welcome to DemoGPT, a revolutionary open-source initiative that is reshaping the landscape of Large Language Model (LLM) based application development.

At the heart of DemoGPT, the capabilities of GPT-3.5-turbo come to life, driving the automatic generation of LangChain code. This process is enriched with a sophisticated architecture that translates user instructions into interactive Streamlit applications.

### How DemoGPT Works

1. **Planning:** DemoGPT starts by generating a plan from the user's instruction.
2. **Task Creation:** It then creates specific tasks from the plan and instruction.
3. **Code Snippet Generation:** These tasks are transferred into code snippets.
4. **Final Code Assembly:** The code snippets are combined into a final code, resulting in an interactive Streamlit app.

The LangChain code, once generated, is not a mere endpoint but a transformative stage. It evolves into a user-friendly Streamlit application, adding an interactive dimension to the logic crafted. This metamorphosis embodies DemoGPT's commitment to user engagement and experience.

### Future Enhancements

We are planning to add a publicly available database that will accelerate the generation process by retrieving similar examples during the refining process. This innovation will further streamline the development workflow, making it more efficient and responsive.

### Model Flexibility

DemoGPT is designed to be adaptable, capable of using any LLM model that meets specific performance criteria in terms of code generation. This flexibility ensures that DemoGPT remains at the forefront of technology, embracing new advancements in LLM.

DemoGPT's iterative development process remains a cornerstone of its innovation. Each code segment undergoes individual testing, and the self-refining strategy ensures an efficient and error-minimized workflow. This fusion of meticulous testing and refinement is a testament to DemoGPT's pursuit of excellence.

By transcending traditional coding paradigms, DemoGPT is pioneering a new era in LLM-based applications. It's not just about code generation; it's about crafting intelligent, interactive, and inclusive solutions.

In summary, DemoGPT is more than a project; it's a visionary approach, pushing the boundaries of what's possible in LLM-based application development.

In the next release, we are gonna integrate **Gorilla** to DemoGPT to enable DemoGPT to use external APIs autonomously. The future is bright, and the journey has just begun. Join us in this exciting adventure!


## ‚öôÔ∏è Architecture
### DemoGPT Architecture
![DemoGPT Architecture](assets/plan_based_pipeline.png?raw=true "DemoGPT Architecture")

## üîß Installation

### For the Package Version

You can install the DemoGPT package by running the following command:

```sh
pip install demogpt
```

### For the Source Code Version


1. Clone the repository:
    ```sh
    git clone https://github.com/melih-unsal/DemoGPT.git
    ```
2. Navigate into the project directory:
    ```sh
    cd DemoGPT
    ```
3. Install DemoGPT: 
    ```sh
    pip install .
    ```

## üéÆ Usage

### üì¶ For the Package Version

Once the DemoGPT package is installed, you can use it by running the following command in your terminal:

```sh
demogpt
```

### üêç For the Python Interface

You can now use DemoGPT as a library in your Python applications:

```python
from demogpt import DemoGPT
agent = DemoGPT(model_name="gpt-3.5-turbo") # if OPENAI_API_KEY is not set in env variables, put it with openai_api_key argument
instruction = "Your instruction here"
title = "Your title here"
code = ""
for phase in agent(instruction=instruction, title=title):
    print(phase) # this will display the resulting json for each generation stage
    if phase["done"]:
        code = phase["code"] # final code
print(code)
```

Example Output (truncated):

```bash
# phases
{'stage': 'draft', 'completed': False, 'percentage': 60, ...}
{'stage': 'draft', 'completed': False, 'percentage': 64, 'code': '#Get the source language ...'}
...
{'stage': 'final', 'completed': True, 'percentage': 100, ... , 'code': 'import streamlit as st\n...'}
```

```python
# Code
import streamlit as st
from langchain.chains import LLMChain
from langchain_community.chat_models import ChatOpenAI
from langchain.prompts.chat import (ChatPromptTemplate,
                                    HumanMessagePromptTemplate,
                                    SystemMessagePromptTemplate)
...
```

### üåê For the Source Code Version

If you have cloned the repository and wish to run the source code version, you can use DemoGPT by running the following command:

```sh
streamlit run demogpt/app.py
```

## To-Do üìù
- [x] Implement new DemoGPT pipeline including plan generation, task creation, code snippet generation, and final code assembly.
- [x] Add feature to allow users to select models.
- [x] Define useful LangChain tasks
- [x] Publish release with the new pipeline without refinement
- [ ] Implement remaining LangChain tasks
- [ ] Implement self-refining strategy for model response refinement.
- [ ] Integrate ü¶ç Gorilla model for API calls.
- [ ] Add Rapid API for expanding available API calls. 
- [ ] Add ü¶ô Llama2 integration
- [ ] Implement publicly available database to accelerate the generation process by retrieving similar examples during the refining process.
- [ ] Add all successfully generated steps to a DB to eliminate redundant refinement.

## ü§ù Contribute

Contributions to the DemoGPT project are welcomed! Whether you're fixing bugs, improving the documentation, or proposing new features, your efforts are highly appreciated. Please check the open issues before starting any work.

> Please read [`CONTRIBUTING`](CONTRIBUTING.md) for details on our [`CODE OF CONDUCT`](CODE_OF_CONDUCT.md), and the process for submitting pull requests to us.

## üìÑ Citations

DemoGPT has been referenced in various research papers for its innovative approach to app creation using autonomous AI agents. Below is a list of papers that have cited DemoGPT:

- Lei Wang, Chen Ma , Xueyang Feng , Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin , Zhao, Zhewei Wei, Ji-Rong Wen, "A Survey on Large Language Model based Autonomous Agents", 2023. [Link to paper](https://arxiv.org/pdf/2308.11432.pdf)
- Yuan Li, Yixuan Zhang, Lichao Sun, "METAAGENTS: SIMULATING INTERACTIONS OF HUMAN BEHAVIORS FOR LLM-BASED TASK-ORIENTED COORDINATION VIA COLLABORATIVE GENERATIVE AGENTS" Journal/Conference, 2023. [Link to paper](https://arxiv.org/pdf/2310.06500.pdf)
- Yuheng Cheng, Ceyao Zhang, Zhengwen Zhang, Xiangrui Meng, Sirui Hong, Wenhao Li, Zihao Wang, Zekai Wang, Feng Yin, Junhua Zhao, Xiuqiang He, "EXPLORING LARGE LANGUAGE MODEL BASED INTELLIGENT AGENTS: DEFINITIONS, METHODS, AND PROSPECTS", 2024. [Link to paper](https://arxiv.org/pdf/2401.03428.pdf)
- Mikhail, Poludin. Optimalizace LLM agent≈Ø pro anal√Ωzu tabulkov√Ωch dat: Integrace LoRA pro zv√Ω≈°en√≠ kvality. MS thesis. ƒåesk√© vysok√© uƒçen√≠ technick√© v Praze. Vypoƒçetn√≠ a informaƒçn√≠ centrum., 2024. [Link to paper](https://dspace.cvut.cz/bitstream/handle/10467/115388/F3-DP-2024-Poludin-Mikhail-Optimizing_LLM-Powered_Agents_for_Tabular_Data_Analytics_Integrating_LoRA_for_Enhanced_Quality.pdf?sequence=-1)

This acknowledgment from the academic community highlights the potential and utility of DemoGPT in advancing the field of AI-driven development tools.


## üìú License

DemoGPT is an open-source project licensed under [MIT License](LICENSE).

---

For any issues, questions, or comments, please feel free to contact us or open an issue. We appreciate your feedback to make DemoGPT better.
